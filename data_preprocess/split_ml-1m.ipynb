{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Job</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>Movie title</th>\n",
       "      <th>Movie genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>labels</th>\n",
       "      <th>history ID</th>\n",
       "      <th>history rating</th>\n",
       "      <th>shared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978131240</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>18-24</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>01609</td>\n",
       "      <td>2700</td>\n",
       "      <td>South Park: Bigger, Longer and Uncut (1999)</td>\n",
       "      <td>Animation</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[2253, 1198, 2628, 2028, 2683, 2355, 223, 2712...</td>\n",
       "      <td>[4, 5, 5, 5, 3, 3, 5, 4, 5, 4, 4, 5, 5, 4, 4, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978131266</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>18-24</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>01609</td>\n",
       "      <td>2693</td>\n",
       "      <td>Trekkies (1997)</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[2253, 1198, 2628, 2028, 2683, 2355, 223, 2712...</td>\n",
       "      <td>[4, 5, 5, 5, 3, 3, 5, 4, 5, 4, 4, 5, 5, 4, 4, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978131266</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>18-24</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>01609</td>\n",
       "      <td>3114</td>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>Animation</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[2253, 1198, 2628, 2028, 2683, 2355, 223, 2712...</td>\n",
       "      <td>[4, 5, 5, 5, 3, 3, 5, 4, 5, 4, 4, 5, 5, 4, 4, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>978131277</td>\n",
       "      <td>48</td>\n",
       "      <td>male</td>\n",
       "      <td>25-34</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>92107</td>\n",
       "      <td>2288</td>\n",
       "      <td>Thing, The (1982)</td>\n",
       "      <td>Action</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[66, 569, 1197, 552, 1193, 2054, 2152, 3897, 3...</td>\n",
       "      <td>[1, 2, 3, 3, 4, 2, 1, 4, 4, 4, 3, 3, 3, 3, 5, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>978131283</td>\n",
       "      <td>25</td>\n",
       "      <td>male</td>\n",
       "      <td>18-24</td>\n",
       "      <td>college/grad student</td>\n",
       "      <td>01609</td>\n",
       "      <td>2987</td>\n",
       "      <td>Who Framed Roger Rabbit? (1988)</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[2253, 1198, 2628, 2028, 2683, 2355, 223, 2712...</td>\n",
       "      <td>[4, 5, 5, 5, 3, 3, 5, 4, 5, 4, 4, 5, 5, 4, 4, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  User ID Gender    Age                   Job Zipcode  Movie ID  \\\n",
       "0  978131240       25   male  18-24  college/grad student   01609      2700   \n",
       "1  978131266       25   male  18-24  college/grad student   01609      2693   \n",
       "2  978131266       25   male  18-24  college/grad student   01609      3114   \n",
       "3  978131277       48   male  25-34  college/grad student   92107      2288   \n",
       "4  978131283       25   male  18-24  college/grad student   01609      2987   \n",
       "\n",
       "                                   Movie title  Movie genre  rating  labels  \\\n",
       "0  South Park: Bigger, Longer and Uncut (1999)    Animation       2       0   \n",
       "1                              Trekkies (1997)  Documentary       3       0   \n",
       "2                           Toy Story 2 (1999)    Animation       4       1   \n",
       "3                            Thing, The (1982)       Action       3       0   \n",
       "4              Who Framed Roger Rabbit? (1988)    Adventure       4       1   \n",
       "\n",
       "                                          history ID  \\\n",
       "0  [2253, 1198, 2628, 2028, 2683, 2355, 223, 2712...   \n",
       "1  [2253, 1198, 2628, 2028, 2683, 2355, 223, 2712...   \n",
       "2  [2253, 1198, 2628, 2028, 2683, 2355, 223, 2712...   \n",
       "3  [66, 569, 1197, 552, 1193, 2054, 2152, 3897, 3...   \n",
       "4  [2253, 1198, 2628, 2028, 2683, 2355, 223, 2712...   \n",
       "\n",
       "                                      history rating  shared  \n",
       "0  [4, 5, 5, 5, 3, 3, 5, 4, 5, 4, 4, 5, 5, 4, 4, ...       2  \n",
       "1  [4, 5, 5, 5, 3, 3, 5, 4, 5, 4, 4, 5, 5, 4, 4, ...       3  \n",
       "2  [4, 5, 5, 5, 3, 3, 5, 4, 5, 4, 4, 5, 5, 4, 4, ...       0  \n",
       "3  [1, 2, 3, 3, 4, 2, 1, 4, 4, 4, 3, 3, 3, 3, 5, ...       2  \n",
       "4  [4, 5, 5, 5, 3, 3, 5, 4, 5, 4, 4, 5, 5, 4, 4, ...       2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理ml-1m\n",
    "import json \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "valid_df = pd.read_parquet(os.path.join('../data/ml-1m/proc_data/valid.parquet.gz'))\n",
    "test_df = pd.read_parquet(os.path.join('../data/ml-1m/proc_data/test.parquet.gz'))\n",
    "df = pd.concat([valid_df,test_df])\n",
    "df = df.iloc[-100000:]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "df['shared'] = np.random.choice([0,1,2,3],size=len(df))\n",
    "train_df = df.iloc[:int(0.6*df.shape[0])]\n",
    "print(train_df.shape[0])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_dir = '../data/ml-1m/proc_data/data/'\n",
    "\n",
    "with open(data_dir+'rella_valid/valid_10_simple.json', 'r') as f:\n",
    "    rella_train_data = json.load(f)\n",
    "with open(data_dir+'rella_test/test_10_simple.json', 'r') as f:\n",
    "    rella_test_data = json.load(f)\n",
    "rella_data = rella_train_data + rella_test_data\n",
    "length = len(rella_data)\n",
    "# print(\"rella data length: \", length)\n",
    "rella_data = rella_data[-100000:]\n",
    "length = len(rella_data)\n",
    "# print(\"rella data length: \", length)\n",
    "\n",
    "train_data, valid_data, test_data = rella_data[:int(0.6*length)], rella_data[int(0.6*length):int(0.8*length)], rella_data[int(0.8*length):]\n",
    "# print(len(train_data), len(valid_data), len(test_data))\n",
    "os.makedirs(data_dir+'train', exist_ok=True)\n",
    "os.makedirs(data_dir+'valid', exist_ok=True)\n",
    "os.makedirs(data_dir+'test', exist_ok=True)\n",
    "with open(data_dir+f'train/train_10_simple.json', 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "with open(data_dir+f'valid/valid_10_simple.json', 'w') as f:\n",
    "    json.dump(valid_data, f)\n",
    "with open(data_dir+f'test/test_10_simple.json', 'w') as f:\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "1025\n",
      "12982 47018\n"
     ]
    }
   ],
   "source": [
    "with open(data_dir+'train/train_10_simple.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "length = len(train_data)\n",
    "print(length)\n",
    "\n",
    "unique_user_list = train_df['User ID'].unique()\n",
    "user_num = len(unique_user_list)\n",
    "print(user_num)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(unique_user_list)\n",
    "\n",
    "# 将train进一步划分成 retain data 和 forget data\n",
    "for p in [0.2]:\n",
    "    forget_user = unique_user_list[:int(p*user_num)]\n",
    "    # print(forget_user)\n",
    "    # print(len(forget_user))\n",
    "    selected_index = train_df[train_df['User ID'].isin(forget_user)].index\n",
    "    selected_index = selected_index.tolist()\n",
    "    # print(len(selected_index))\n",
    "    forget_data = [record for idx, record in enumerate(train_data) if idx in selected_index ]\n",
    "    retain_data = [record for idx, record in enumerate(train_data) if idx not in selected_index  ]\n",
    "    print(len(forget_data), len(retain_data))\n",
    "    with open(data_dir+f'train/retain_{p}_user_10_simple.json', 'w') as f:\n",
    "        json.dump(retain_data, f)\n",
    "    with open(data_dir+f'train/forget_{p}_user_10_simple.json', 'w') as f:\n",
    "        json.dump(forget_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "1025\n",
      "205\n",
      "11770\n",
      "205\n",
      "11739\n",
      "205\n",
      "11759\n",
      "205\n",
      "11750\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(data_dir+'train/train_10_simple.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "length = len(train_data)\n",
    "print(length)\n",
    "\n",
    "unique_user_list = train_df['User ID'].unique()\n",
    "user_num = len(unique_user_list)\n",
    "print(user_num)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(unique_user_list)\n",
    "\n",
    "os.makedirs(data_dir+'sisa', exist_ok=True)\n",
    "# sisa方法：每个shard去掉forget data\n",
    "for shared in [0,1,2,3]:\n",
    "    for p in [0.2]:\n",
    "        forget_user = unique_user_list[:int(p*user_num)]\n",
    "        print(len(forget_user))\n",
    "        shared_index = train_df[train_df['shared'] == shared].index\n",
    "        shared_index = shared_index.tolist()\n",
    "        \n",
    "        forget_index = train_df[train_df['User ID'].isin(forget_user)].index\n",
    "        forget_index = forget_index.tolist()\n",
    "\n",
    "        retain_data = [record for idx, record in enumerate(train_data) if idx not in forget_index and idx in shared_index]\n",
    "        print(len(retain_data))\n",
    "        # 保存每个shared中去掉forget data之后的数据\n",
    "        with open(data_dir+f'sisa/shared_{shared}_{p}_user_10_simple.json', 'w') as f:\n",
    "            json.dump(retain_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length: 60000\n",
      "train data user num: 1025\n",
      "205\n",
      "11416\n",
      "205\n",
      "10909\n",
      "205\n",
      "11576\n",
      "205\n",
      "13117\n"
     ]
    }
   ],
   "source": [
    "# 划分eraser\n",
    "import json\n",
    "\n",
    "with open(data_dir+'train/train_10_simple.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "length = len(train_data)\n",
    "print('train data length:', length)\n",
    "\n",
    "unique_user_list = train_df['User ID'].unique()\n",
    "user_num = len(unique_user_list)\n",
    "print('train data user num:', user_num)\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(unique_user_list)\n",
    "\n",
    "for p in [0.2]:\n",
    "    for shared in [0,1,2,3]:\n",
    "        forget_user = unique_user_list[:int(p*user_num)]\n",
    "        # print(len(forget_user))\n",
    "        retain_user = unique_user_list[int(p*user_num):]\n",
    "        # print(len(retain_user))\n",
    "        shared_user = retain_user[int(len(retain_user)*shared/4):int(len(retain_user)*(shared+1)/4)]\n",
    "        print(len(shared_user))\n",
    "        shared_index = train_df[train_df['User ID'].isin(shared_user)].index\n",
    "        shared_index = shared_index.tolist()\n",
    "        \n",
    "        forget_index = train_df[train_df['User ID'].isin(forget_user)].index\n",
    "        forget_index = forget_index.tolist()\n",
    "\n",
    "        retain_data = [record for idx, record in enumerate(train_data) if idx not in forget_index and idx in shared_index]\n",
    "        print(len(retain_data))\n",
    "        # 保存每个shared中去掉forget data之后的数据\n",
    "        with open(data_dir+f'sisa/eraser_{shared}_{p}_user_10_simple.json', 'w') as f:\n",
    "            json.dump(retain_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rella",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
